7.1.4 DNN的输出表示
	 在语音识别中或其他信息处理应用中，大多数深度学习方法关注输入声学模型的学习表示，并未关注输出表示。最近2013NIPS Workshop关于学习输出表示(http://nips.cc/Conferences/2013/Program/event.php?ID=3714)致力于弥补这一差距。例如，将在第11节讨论的[117]中描述的深度可视语义嵌入式模型，探索嵌入文本连续值输出表示，将辅助深度神经网络对图像分类。在语音识别中，[79]中强调设计神经网络输出层有效语言表示的重要性。
	 大多数现在的DNN系统使用高维的输出层表示，匹配HMM中上下文依赖的音素状态。因此，输出层求值花费1/3的总计算时间。为了提高解码速度，通常应用low-rank近似到输出层。[310]和[397]中，首先训练高维输出层的DNN。然后应用基于奇异值分解（SVD）降维方法到大输出层矩阵。输出矩阵更近一步合并，用两个小矩阵乘积作为原始大权值矩阵的的近似结果。这种技巧实质上将原始大输出层转换为两层——一个bottleneck线性层和一个非线性输出层——两者都具有很小的权重。降维转换后的DNN被进一步精炼。实验结果表明，即使输出层大小减少一半，识别准确率并无降低，同时显著减少了计算时间。
	 [79]中提，出语音识别的输出表示可以从符号或语言单位的设计结构中获益。众所周知，人类语言具有符号特性的语义单元。同样，长久以来，使用音素或它细粒度的状态序列，甚至上下文依赖的三音素，对于表示这种丰富结构[86, 273, 355]也是远远不足的。因此，这也是提高语音识别系统性能的有前途的方向。语音内部结构的基本理论和语音识别技术密切相关，[76]和更近的[79]调查在现有语音模型下，抽象、设计、学习其他可能的输出表示。
	 语音识别中使用深度学习方法,研究关注于相关语言结构的输出层表示的设计，正在不断成长。[383, 384]中，说明输出层表示设计的限制，[67,68]中提出基于上下文相关的音素单元，被认为是一种解决方案。这种限制的根本原因是决策树创建的聚类使上下文依赖的音素状态共享权值，这降低了解码阶段更细粒度的分辨率能力。提出的解决方案为公理化上下文依赖的DNN输出表示，作为标准状态建模技术的一个实例，使用更多的音素类。首先，三音素使用更宽上下文被聚类为更小的两音素的集合。然后，训练DNN区分这些两音素集合。使用逻辑回归将标准状态分类为更详尽的三音素状态输出概率。即上下文依赖的DNN输出层表示的总体设计，是自然的分层结构，同时解决了数据稀疏性问题和低分辨率问题。
	设计语音识别输出层语言表示的其他相关工作可以参考[197]和[241]，其中这些基于上下文依赖的GMM-HMM系统的设计，同样可以扩展到深度学习的模型中。
